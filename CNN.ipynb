{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8BFMt_dzxnH"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files       \n",
        "from keras.utils import np_utils\n",
        "import numpy as np \n",
        "from glob import glob \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# define function to load datasets\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']), 36)\n",
        "    return files, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rS57364z84Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f8430f-b9ed-4721-cffe-fa2f08dd2118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoidhBXq0Dfg"
      },
      "outputs": [],
      "source": [
        "# load train, test, and validation datasets\n",
        "data_files, data_targets = load_dataset('/content/drive/MyDrive/ASL_FingerSpelling_Dataset')\n",
        "# load list of names\n",
        "names = [item[17:19] for item in sorted(glob(\"/content/drive/MyDrive/ASL_FingerSpelling_Dataset/*/\"))]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_files, data_targets, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epqyzPx40JBH",
        "outputId": "5a017dbb-a400-48e4-b244-4ef4d8eb7318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2515 total images.\n",
            "\n",
            "There are 2012 training images.\n",
            "There are 36 total categories.\n",
            "There are 503 testing images.\n"
          ]
        }
      ],
      "source": [
        "# print statistics about the dataset\n",
        "\n",
        "print('There are %s total images.\\n' % len(np.hstack([X_train, X_test])))\n",
        "print('There are %d training images.' % len(X_train))\n",
        "print('There are %d total categories.' % len(names))\n",
        "print('There are %d testing images.' % len(X_test)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kCVBNfD0Lbo"
      },
      "outputs": [],
      "source": [
        "# Pre-process the Data\n",
        "from keras_preprocessing import image                  \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGBViJQZ0NYu",
        "outputId": "4e67ef04-86a5-49e3-9822-efdfd51e4aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2012/2012 [00:07<00:00, 263.28it/s]\n",
            "100%|██████████| 503/503 [00:04<00:00, 121.84it/s]\n"
          ]
        }
      ],
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
        "\n",
        "# pre-process the data for Keras\n",
        "train_targets=y_train\n",
        "test_targets=y_test\n",
        "train_tensors = paths_to_tensor(X_train).astype('float32')/255  \n",
        "test_tensors = paths_to_tensor(X_test).astype('float32')/255 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_7QpjZ0Phj",
        "outputId": "fd12e802-1130-4452-883d-fc2151de131b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 128)     32896     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 256)       131328    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 512)       524800    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               50176500  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 36)                18036     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,884,392\n",
            "Trainable params: 50,884,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(224,224,3), kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "#model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(36, activation='softmax', kernel_initializer='glorot_normal'))\n",
        "\n",
        "\n",
        "### TODO: Define your architecture.\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KazY3Hiy0ShE"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "##Model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
        "##Model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "##Model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKvkbPdm0UWX",
        "outputId": "4e60d940-7ad1-4173-c514-d4d1b546f770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 3.2044 - accuracy: 0.2746\n",
            "Epoch 1: val_accuracy improved from -inf to 0.68317, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 23s 240ms/step - loss: 3.2044 - accuracy: 0.2746 - val_loss: 1.0619 - val_accuracy: 0.6832\n",
            "Epoch 2/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.9137 - accuracy: 0.7320\n",
            "Epoch 2: val_accuracy improved from 0.68317 to 0.79703, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 10s 218ms/step - loss: 0.9137 - accuracy: 0.7320 - val_loss: 0.8358 - val_accuracy: 0.7970\n",
            "Epoch 3/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8536\n",
            "Epoch 3: val_accuracy improved from 0.79703 to 0.86634, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 10s 217ms/step - loss: 0.4544 - accuracy: 0.8536 - val_loss: 0.4243 - val_accuracy: 0.8663\n",
            "Epoch 4/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9188\n",
            "Epoch 4: val_accuracy improved from 0.86634 to 0.94554, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 10s 223ms/step - loss: 0.2536 - accuracy: 0.9188 - val_loss: 0.2400 - val_accuracy: 0.9455\n",
            "Epoch 5/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9475\n",
            "Epoch 5: val_accuracy did not improve from 0.94554\n",
            "46/46 [==============================] - 9s 193ms/step - loss: 0.1710 - accuracy: 0.9475 - val_loss: 0.1663 - val_accuracy: 0.9307\n",
            "Epoch 6/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9597\n",
            "Epoch 6: val_accuracy improved from 0.94554 to 0.97030, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 10s 220ms/step - loss: 0.1385 - accuracy: 0.9597 - val_loss: 0.1796 - val_accuracy: 0.9703\n",
            "Epoch 7/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9707\n",
            "Epoch 7: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 195ms/step - loss: 0.0753 - accuracy: 0.9707 - val_loss: 0.1945 - val_accuracy: 0.9455\n",
            "Epoch 8/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9779\n",
            "Epoch 8: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 202ms/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 0.1629 - val_accuracy: 0.9653\n",
            "Epoch 9/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9768\n",
            "Epoch 9: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 196ms/step - loss: 0.0554 - accuracy: 0.9768 - val_loss: 0.1482 - val_accuracy: 0.9653\n",
            "Epoch 10/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9873\n",
            "Epoch 10: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0483 - accuracy: 0.9873 - val_loss: 0.1536 - val_accuracy: 0.9653\n",
            "Epoch 11/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9884\n",
            "Epoch 11: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.1466 - val_accuracy: 0.9653\n",
            "Epoch 12/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9901\n",
            "Epoch 12: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.1831 - val_accuracy: 0.9703\n",
            "Epoch 13/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 0.97030\n",
            "46/46 [==============================] - 9s 201ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.1982 - val_accuracy: 0.9703\n",
            "Epoch 14/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9906\n",
            "Epoch 14: val_accuracy improved from 0.97030 to 0.97525, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 10s 229ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 0.2244 - val_accuracy: 0.9752\n",
            "Epoch 15/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9917\n",
            "Epoch 15: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.2247 - val_accuracy: 0.9703\n",
            "Epoch 16/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9950\n",
            "Epoch 16: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 10s 208ms/step - loss: 0.0123 - accuracy: 0.9950 - val_loss: 0.3338 - val_accuracy: 0.9604\n",
            "Epoch 17/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9923\n",
            "Epoch 17: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0188 - accuracy: 0.9923 - val_loss: 0.3150 - val_accuracy: 0.9703\n",
            "Epoch 18/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9956\n",
            "Epoch 18: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0219 - accuracy: 0.9956 - val_loss: 0.2314 - val_accuracy: 0.9703\n",
            "Epoch 19/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9950\n",
            "Epoch 19: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 205ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.3503 - val_accuracy: 0.9703\n",
            "Epoch 20/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9923\n",
            "Epoch 20: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0198 - accuracy: 0.9923 - val_loss: 0.2822 - val_accuracy: 0.9752\n",
            "Epoch 21/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
            "Epoch 21: val_accuracy did not improve from 0.97525\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1878 - val_accuracy: 0.9752\n",
            "Epoch 22/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9945\n",
            "Epoch 22: val_accuracy improved from 0.97525 to 0.98020, saving model to /content/sample_data/weights.best.from_scratch_new.hdf5\n",
            "46/46 [==============================] - 11s 234ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.2069 - val_accuracy: 0.9802\n",
            "Epoch 23/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 23: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3278 - val_accuracy: 0.9703\n",
            "Epoch 24/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
            "Epoch 24: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.3236 - val_accuracy: 0.9802\n",
            "Epoch 25/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9967\n",
            "Epoch 25: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 206ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.3262 - val_accuracy: 0.9703\n",
            "Epoch 26/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978\n",
            "Epoch 26: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.3802 - val_accuracy: 0.9802\n",
            "Epoch 27/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9950\n",
            "Epoch 27: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 199ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.2950 - val_accuracy: 0.9703\n",
            "Epoch 28/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9967\n",
            "Epoch 28: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 10s 208ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.3244 - val_accuracy: 0.9604\n",
            "Epoch 29/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9978\n",
            "Epoch 29: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 200ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.3003 - val_accuracy: 0.9653\n",
            "Epoch 30/30\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9978\n",
            "Epoch 30: val_accuracy did not improve from 0.98020\n",
            "46/46 [==============================] - 9s 206ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.3462 - val_accuracy: 0.9752\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint  \n",
        "\n",
        "### TODO: specify the number of epochs that you would like to use to train the model.\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "### Do NOT modify the code below this line.\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/content/sample_data/weights.best.from_scratch_new.hdf5', \n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "history=model.fit(train_tensors, train_targets, validation_split=0.1, epochs=epochs, batch_size=40, callbacks=[checkpointer], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHvSFvMT0a8Z"
      },
      "outputs": [],
      "source": [
        "model.load_weights('/content/sample_data/weights.best.from_scratch_new.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYwRn7Un0hMY",
        "outputId": "3623d6a1-da82-455c-cd0d-7c190d545505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 304ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Time Taken: 30.40876340866089 seconds\n"
          ]
        }
      ],
      "source": [
        "# get index of predicted dog breed for each image in test set\n",
        "#dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
        "import time\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "predictions = [model.predict(np.expand_dims(tensor, axis=0))[0] for tensor in test_tensors]\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "print(\"Time Taken: {} seconds\".format(end_time-start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enWcWyJS0kJR",
        "outputId": "42ec1e12-4e41-4625-f394-54b5be012b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.90        16\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       1.00      1.00      1.00        13\n",
            "           5       1.00      1.00      1.00        17\n",
            "           6       1.00      0.94      0.97        18\n",
            "           7       1.00      1.00      1.00        13\n",
            "           8       1.00      1.00      1.00        16\n",
            "           9       1.00      1.00      1.00        17\n",
            "          10       1.00      1.00      1.00        19\n",
            "          11       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00        11\n",
            "          13       0.95      1.00      0.98        20\n",
            "          14       1.00      1.00      1.00        19\n",
            "          15       1.00      1.00      1.00        11\n",
            "          16       0.84      1.00      0.91        21\n",
            "          17       1.00      1.00      1.00        10\n",
            "          18       1.00      1.00      1.00        13\n",
            "          19       1.00      0.75      0.86        16\n",
            "          20       1.00      1.00      1.00        14\n",
            "          21       1.00      1.00      1.00        10\n",
            "          22       1.00      1.00      1.00        11\n",
            "          23       1.00      0.87      0.93        15\n",
            "          24       0.85      0.92      0.88        12\n",
            "          25       1.00      1.00      1.00        17\n",
            "          26       1.00      1.00      1.00        20\n",
            "          27       0.92      1.00      0.96        11\n",
            "          28       0.92      1.00      0.96        11\n",
            "          29       0.92      1.00      0.96        11\n",
            "          30       1.00      0.94      0.97        18\n",
            "          31       1.00      1.00      1.00         7\n",
            "          32       0.89      1.00      0.94         8\n",
            "          33       1.00      1.00      1.00         9\n",
            "          34       1.00      1.00      1.00        18\n",
            "          35       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           0.98       503\n",
            "   macro avg       0.98      0.98      0.98       503\n",
            "weighted avg       0.98      0.98      0.98       503\n",
            "\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [ 0 10  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  9  0  0]\n",
            " [ 0  0  0 ...  0 18  0]\n",
            " [ 0  0  0 ...  0  0 14]]\n"
          ]
        }
      ],
      "source": [
        "predicted_classes = np.argmax(np.round(predictions),axis=1)\n",
        "test_classes = np.argmax(np.round(test_targets),axis=1)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_classes, predicted_classes))\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_mtx = confusion_matrix(test_classes, predicted_classes)\n",
        "print(confusion_mtx)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}