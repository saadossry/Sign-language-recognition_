{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND-5sxK0Dg6o"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files       \n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# define function to load datasets\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']), 36)\n",
        "    return files, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRF3AKQnvxMP",
        "outputId": "89350959-ef4d-49ad-af89-88d8439d480c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sJSQ2KUoIPF"
      },
      "outputs": [],
      "source": [
        "# load train, test, and validation datasets\n",
        "data_files, data_targets = load_dataset('/content/drive/MyDrive/ASL_FingerSpelling_Dataset')\n",
        "# load list of names\n",
        "names = [item[17:19] for item in sorted(glob(\"/content/drive/MyDrive/ASL_FingerSpelling_Dataset/*/\"))]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_files, data_targets, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtqc0GiFKNHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1b1465-6bda-42eb-9f76-4bd097f7f69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2515 total images.\n",
            "\n",
            "There are 2012 training images.\n",
            "There are 36 total categories.\n",
            "There are 503 testing images.\n"
          ]
        }
      ],
      "source": [
        "# print statistics about the dataset\n",
        "##fig = plt.Figure=(figsize=(20,5))\n",
        "print('There are %s total images.\\n' % len(np.hstack([X_train, X_test])))\n",
        "print('There are %d training images.' % len(X_train))\n",
        "print('There are %d total categories.' % len(names))\n",
        "print('There are %d testing images.' % len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKwJvjPfJrJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75badbd3-36de-4d3e-817c-642ef6e6cc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "# Pre-process the Data\n",
        "!pip install keras_preprocessing\n",
        "\n",
        "from keras_preprocessing import image                  \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B-ZiXSLM80o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f769b627-e5a2-46d7-f099-9d7ec8f8f175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2012/2012 [00:11<00:00, 171.70it/s]\n",
            "100%|██████████| 503/503 [00:03<00:00, 158.57it/s]\n"
          ]
        }
      ],
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
        "\n",
        "# pre-process the data for Keras\n",
        "train_targets=y_train\n",
        "test_targets=y_test\n",
        "train_tensors = paths_to_tensor(X_train).astype('float32')/255\n",
        "test_tensors = paths_to_tensor(X_test).astype('float32')/255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "model2 = ResNet50(include_top=False,pooling= 'avg')\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "8h7GA-4XJuAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223378f0-2b06-4314-8a07-e3e814640882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_2[0][0]']                \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, None, None,   256         ['conv1_conv[0][0]']             \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, None, None,   0           ['conv1_bn[0][0]']               \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_relu[0][0]']             \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, None, None,   4160        ['pool1_pool[0][0]']             \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['pool1_pool[0][0]']             \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, None, None,   0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                256)                              'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, None, None,   0           ['conv2_block1_add[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block1_out[0][0]']       \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n",
            "                                256)                              'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, None, None,   0           ['conv2_block2_add[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block2_out[0][0]']       \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                       64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n",
            " n)                             64)                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, None, None,   0           ['conv2_block2_out[0][0]',       \n",
            "                                256)                              'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, None, None,   0           ['conv2_block3_add[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, None, None,   32896       ['conv2_block3_out[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv2_block3_out[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, None, None,   0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                512)                              'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, None, None,   0           ['conv3_block1_add[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block1_out[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n",
            "                                512)                              'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, None, None,   0           ['conv3_block2_add[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block2_out[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n",
            "                                512)                              'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, None, None,   0           ['conv3_block3_add[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block3_out[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                       128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                             128)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, None, None,   0           ['conv3_block3_out[0][0]',       \n",
            "                                512)                              'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, None, None,   0           ['conv3_block4_add[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, None, None,   131328      ['conv3_block4_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv3_block4_out[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, None, None,   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                1024)                             'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, None, None,   0           ['conv4_block1_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block1_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n",
            "                                1024)                             'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, None, None,   0           ['conv4_block2_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block2_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n",
            "                                1024)                             'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, None, None,   0           ['conv4_block3_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block3_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n",
            "                                1024)                             'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, None, None,   0           ['conv4_block4_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block4_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n",
            "                                1024)                             'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, None, None,   0           ['conv4_block5_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block5_out[0][0]']       \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                       256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                             256)                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       1024)                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, None, None,   0           ['conv4_block5_out[0][0]',       \n",
            "                                1024)                             'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, None, None,   0           ['conv4_block6_add[0][0]']       \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, None, None,   524800      ['conv4_block6_out[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                       2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                       2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, None, None,   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                2048)                             'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, None, None,   0           ['conv5_block1_add[0][0]']       \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block1_out[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                       2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n",
            "                                2048)                             'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, None, None,   0           ['conv5_block2_add[0][0]']       \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block2_out[0][0]']       \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                       512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n",
            " n)                             512)                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                       2048)                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n",
            "                                2048)                             'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, None, None,   0           ['conv5_block3_add[0][0]']       \n",
            "                                2048)                                                             \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFve8tjc_7oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f3464a-2c3a-4af7-ea08-951a26512da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        }
      ],
      "source": [
        "bottleneck_features_train_ResNet50 = np.asarray([model2.predict(np.expand_dims(tensor, axis=0), verbose=1)[0] for tensor in train_tensors],dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MQSNMuVAE1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d424859-62bc-481e-d669-52c1e9a1db73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "bottleneck_features_test_ResNet50 = np.asarray([model2.predict(np.expand_dims(tensor, axis=0), verbose=1)[0] for tensor in test_tensors],dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wHJTHOKAPFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5e1ea8-6808-478b-9a7d-3ace98ad6ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2012, 2048)\n",
            "(503, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(bottleneck_features_train_ResNet50.shape)\n",
        "print(bottleneck_features_test_ResNet50.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpfzT8opAUAG"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Activation, GlobalAveragePooling2D, Flatten, Dense\n",
        "Model = Sequential()\n",
        "Model.add(Dense(500, activation='relu',kernel_initializer='glorot_normal'))\n",
        "Model.add(Dense(36, activation='softmax', kernel_initializer='glorot_normal'))\n",
        "##Model.add(Dense(250, activation='relu',kernel_initializer='glorot_normal')) \n",
        "##Model.add(Dense(100, activation='relu',kernel_initializer='glorot_normal')) \n",
        "##Model.add(Dense(50, activation='relu',kernel_initializer='glorot_normal')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4DmG6vSAdPv"
      },
      "outputs": [],
      "source": [
        "##Model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "Model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
        "##Model.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Ff3-qUAk2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b8ec3d-a9bb-43b9-fdd8-ae2cde0b6b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 3.6249 - accuracy: 0.0448\n",
            "Epoch 1: val_accuracy improved from -inf to 0.04950, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 13ms/step - loss: 3.6179 - accuracy: 0.0470 - val_loss: 3.5697 - val_accuracy: 0.0495\n",
            "Epoch 2/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 3.4207 - accuracy: 0.0890\n",
            "Epoch 2: val_accuracy improved from 0.04950 to 0.09901, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 10ms/step - loss: 3.4144 - accuracy: 0.0890 - val_loss: 3.2833 - val_accuracy: 0.0990\n",
            "Epoch 3/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 3.2063 - accuracy: 0.1198\n",
            "Epoch 3: val_accuracy improved from 0.09901 to 0.15842, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 13ms/step - loss: 3.1929 - accuracy: 0.1215 - val_loss: 3.0576 - val_accuracy: 0.1584\n",
            "Epoch 4/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 2.9832 - accuracy: 0.1677\n",
            "Epoch 4: val_accuracy improved from 0.15842 to 0.18317, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 16ms/step - loss: 2.9764 - accuracy: 0.1669 - val_loss: 2.8873 - val_accuracy: 0.1832\n",
            "Epoch 5/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 2.8072 - accuracy: 0.2051\n",
            "Epoch 5: val_accuracy improved from 0.18317 to 0.19307, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 16ms/step - loss: 2.7934 - accuracy: 0.2055 - val_loss: 2.6946 - val_accuracy: 0.1931\n",
            "Epoch 6/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 2.6419 - accuracy: 0.2356\n",
            "Epoch 6: val_accuracy did not improve from 0.19307\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 2.6271 - accuracy: 0.2448 - val_loss: 2.6526 - val_accuracy: 0.1832\n",
            "Epoch 7/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 2.4799 - accuracy: 0.2842\n",
            "Epoch 7: val_accuracy improved from 0.19307 to 0.26238, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 15ms/step - loss: 2.4776 - accuracy: 0.2829 - val_loss: 2.5222 - val_accuracy: 0.2624\n",
            "Epoch 8/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 2.3520 - accuracy: 0.3151\n",
            "Epoch 8: val_accuracy did not improve from 0.26238\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3454 - accuracy: 0.3088 - val_loss: 2.4060 - val_accuracy: 0.2327\n",
            "Epoch 9/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 2.2183 - accuracy: 0.3396\n",
            "Epoch 9: val_accuracy improved from 0.26238 to 0.32673, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 17ms/step - loss: 2.2209 - accuracy: 0.3414 - val_loss: 2.2461 - val_accuracy: 0.3267\n",
            "Epoch 10/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 2.1231 - accuracy: 0.3767\n",
            "Epoch 10: val_accuracy improved from 0.32673 to 0.41089, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 12ms/step - loss: 2.1229 - accuracy: 0.3757 - val_loss: 2.1117 - val_accuracy: 0.4109\n",
            "Epoch 11/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 2.0425 - accuracy: 0.3962\n",
            "Epoch 11: val_accuracy did not improve from 0.41089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0358 - accuracy: 0.4017 - val_loss: 1.9790 - val_accuracy: 0.3960\n",
            "Epoch 12/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 1.9417 - accuracy: 0.4176\n",
            "Epoch 12: val_accuracy did not improve from 0.41089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9385 - accuracy: 0.4182 - val_loss: 1.9860 - val_accuracy: 0.3663\n",
            "Epoch 13/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 1.8454 - accuracy: 0.4506\n",
            "Epoch 13: val_accuracy improved from 0.41089 to 0.43069, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 12ms/step - loss: 1.8475 - accuracy: 0.4492 - val_loss: 1.8309 - val_accuracy: 0.4307\n",
            "Epoch 14/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 1.7801 - accuracy: 0.4774\n",
            "Epoch 14: val_accuracy did not improve from 0.43069\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7760 - accuracy: 0.4790 - val_loss: 1.8732 - val_accuracy: 0.3911\n",
            "Epoch 15/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 1.7178 - accuracy: 0.4756\n",
            "Epoch 15: val_accuracy did not improve from 0.43069\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7114 - accuracy: 0.4785 - val_loss: 1.9204 - val_accuracy: 0.3267\n",
            "Epoch 16/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 1.6632 - accuracy: 0.4786\n",
            "Epoch 16: val_accuracy improved from 0.43069 to 0.49010, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 1.6596 - accuracy: 0.4773 - val_loss: 1.6843 - val_accuracy: 0.4901\n",
            "Epoch 17/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 1.5945 - accuracy: 0.5030\n",
            "Epoch 17: val_accuracy did not improve from 0.49010\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5873 - accuracy: 0.5094 - val_loss: 1.6047 - val_accuracy: 0.4505\n",
            "Epoch 18/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.5486 - accuracy: 0.5112\n",
            "Epoch 18: val_accuracy did not improve from 0.49010\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5519 - accuracy: 0.5094 - val_loss: 1.6364 - val_accuracy: 0.4653\n",
            "Epoch 19/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 1.4932 - accuracy: 0.5381\n",
            "Epoch 19: val_accuracy did not improve from 0.49010\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4929 - accuracy: 0.5348 - val_loss: 1.4691 - val_accuracy: 0.4703\n",
            "Epoch 20/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 1.4311 - accuracy: 0.5539\n",
            "Epoch 20: val_accuracy did not improve from 0.49010\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4387 - accuracy: 0.5536 - val_loss: 1.5706 - val_accuracy: 0.4703\n",
            "Epoch 21/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 1.3925 - accuracy: 0.5715\n",
            "Epoch 21: val_accuracy improved from 0.49010 to 0.56436, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 1.3986 - accuracy: 0.5674 - val_loss: 1.3970 - val_accuracy: 0.5644\n",
            "Epoch 22/250\n",
            "47/57 [=======================>......] - ETA: 0s - loss: 1.3679 - accuracy: 0.5824\n",
            "Epoch 22: val_accuracy did not improve from 0.56436\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.5856 - val_loss: 1.5207 - val_accuracy: 0.4604\n",
            "Epoch 23/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 1.3194 - accuracy: 0.5851\n",
            "Epoch 23: val_accuracy improved from 0.56436 to 0.57921, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 1.3212 - accuracy: 0.5829 - val_loss: 1.2859 - val_accuracy: 0.5792\n",
            "Epoch 24/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 1.2846 - accuracy: 0.5920\n",
            "Epoch 24: val_accuracy improved from 0.57921 to 0.62871, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 1.2845 - accuracy: 0.5917 - val_loss: 1.2891 - val_accuracy: 0.6287\n",
            "Epoch 25/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.2480 - accuracy: 0.6094\n",
            "Epoch 25: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2468 - accuracy: 0.6094 - val_loss: 1.2604 - val_accuracy: 0.5545\n",
            "Epoch 26/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.2107 - accuracy: 0.6133\n",
            "Epoch 26: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2085 - accuracy: 0.6144 - val_loss: 1.2445 - val_accuracy: 0.5842\n",
            "Epoch 27/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 1.1732 - accuracy: 0.6218\n",
            "Epoch 27: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1714 - accuracy: 0.6232 - val_loss: 1.1530 - val_accuracy: 0.6287\n",
            "Epoch 28/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 1.1428 - accuracy: 0.6468\n",
            "Epoch 28: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1448 - accuracy: 0.6470 - val_loss: 1.1806 - val_accuracy: 0.6287\n",
            "Epoch 29/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.1168 - accuracy: 0.6557\n",
            "Epoch 29: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1151 - accuracy: 0.6575 - val_loss: 1.2787 - val_accuracy: 0.5743\n",
            "Epoch 30/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 1.0935 - accuracy: 0.6436\n",
            "Epoch 30: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0982 - accuracy: 0.6387 - val_loss: 1.1377 - val_accuracy: 0.6287\n",
            "Epoch 31/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 1.0615 - accuracy: 0.6678\n",
            "Epoch 31: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0621 - accuracy: 0.6691 - val_loss: 1.2451 - val_accuracy: 0.5594\n",
            "Epoch 32/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 1.0478 - accuracy: 0.6635\n",
            "Epoch 32: val_accuracy did not improve from 0.62871\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0492 - accuracy: 0.6613 - val_loss: 1.1363 - val_accuracy: 0.5990\n",
            "Epoch 33/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 1.0215 - accuracy: 0.6678\n",
            "Epoch 33: val_accuracy improved from 0.62871 to 0.64851, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 10ms/step - loss: 1.0263 - accuracy: 0.6685 - val_loss: 1.0477 - val_accuracy: 0.6485\n",
            "Epoch 34/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.9916 - accuracy: 0.6846\n",
            "Epoch 34: val_accuracy did not improve from 0.64851\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.9976 - accuracy: 0.6829 - val_loss: 1.2040 - val_accuracy: 0.5743\n",
            "Epoch 35/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.9811 - accuracy: 0.6809\n",
            "Epoch 35: val_accuracy improved from 0.64851 to 0.65347, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 13ms/step - loss: 0.9821 - accuracy: 0.6812 - val_loss: 1.0927 - val_accuracy: 0.6535\n",
            "Epoch 36/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.9651 - accuracy: 0.6740\n",
            "Epoch 36: val_accuracy did not improve from 0.65347\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.9606 - accuracy: 0.6762 - val_loss: 1.0312 - val_accuracy: 0.6535\n",
            "Epoch 37/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.9398 - accuracy: 0.6979\n",
            "Epoch 37: val_accuracy improved from 0.65347 to 0.66337, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 25ms/step - loss: 0.9419 - accuracy: 0.6972 - val_loss: 0.9790 - val_accuracy: 0.6634\n",
            "Epoch 38/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.9315 - accuracy: 0.7038\n",
            "Epoch 38: val_accuracy improved from 0.66337 to 0.67822, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 24ms/step - loss: 0.9153 - accuracy: 0.7099 - val_loss: 0.9522 - val_accuracy: 0.6782\n",
            "Epoch 39/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.9000 - accuracy: 0.7049\n",
            "Epoch 39: val_accuracy did not improve from 0.67822\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.9100 - accuracy: 0.7011 - val_loss: 1.0178 - val_accuracy: 0.6584\n",
            "Epoch 40/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.8822 - accuracy: 0.7146\n",
            "Epoch 40: val_accuracy did not improve from 0.67822\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.7193 - val_loss: 0.9610 - val_accuracy: 0.6782\n",
            "Epoch 41/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.8614 - accuracy: 0.7142\n",
            "Epoch 41: val_accuracy did not improve from 0.67822\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.8579 - accuracy: 0.7160 - val_loss: 0.9307 - val_accuracy: 0.6485\n",
            "Epoch 42/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8437 - accuracy: 0.7166\n",
            "Epoch 42: val_accuracy did not improve from 0.67822\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.8437 - accuracy: 0.7166 - val_loss: 1.0450 - val_accuracy: 0.6485\n",
            "Epoch 43/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.8167 - accuracy: 0.7460\n",
            "Epoch 43: val_accuracy improved from 0.67822 to 0.71782, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 10ms/step - loss: 0.8170 - accuracy: 0.7442 - val_loss: 0.9136 - val_accuracy: 0.7178\n",
            "Epoch 44/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.8283 - accuracy: 0.7398\n",
            "Epoch 44: val_accuracy did not improve from 0.71782\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.7381 - val_loss: 0.8802 - val_accuracy: 0.7030\n",
            "Epoch 45/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.7985 - accuracy: 0.7388\n",
            "Epoch 45: val_accuracy did not improve from 0.71782\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.8038 - accuracy: 0.7348 - val_loss: 0.8593 - val_accuracy: 0.6931\n",
            "Epoch 46/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.7963 - accuracy: 0.7352\n",
            "Epoch 46: val_accuracy did not improve from 0.71782\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.7934 - accuracy: 0.7381 - val_loss: 0.8710 - val_accuracy: 0.7129\n",
            "Epoch 47/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.7809 - accuracy: 0.7461\n",
            "Epoch 47: val_accuracy improved from 0.71782 to 0.72772, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.7442 - val_loss: 0.8268 - val_accuracy: 0.7277\n",
            "Epoch 48/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.7489 - accuracy: 0.7595\n",
            "Epoch 48: val_accuracy did not improve from 0.72772\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.7586 - val_loss: 0.9443 - val_accuracy: 0.7079\n",
            "Epoch 49/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.7548 - accuracy: 0.7587\n",
            "Epoch 49: val_accuracy did not improve from 0.72772\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.7569 - val_loss: 0.9486 - val_accuracy: 0.6485\n",
            "Epoch 50/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.7498 - accuracy: 0.7512\n",
            "Epoch 50: val_accuracy did not improve from 0.72772\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.7547 - val_loss: 0.8381 - val_accuracy: 0.7079\n",
            "Epoch 51/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.7235 - accuracy: 0.7618\n",
            "Epoch 51: val_accuracy did not improve from 0.72772\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.7174 - accuracy: 0.7669 - val_loss: 0.8043 - val_accuracy: 0.7079\n",
            "Epoch 52/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.7104 - accuracy: 0.7653\n",
            "Epoch 52: val_accuracy improved from 0.72772 to 0.73762, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 10ms/step - loss: 0.7109 - accuracy: 0.7663 - val_loss: 0.7716 - val_accuracy: 0.7376\n",
            "Epoch 53/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.7018 - accuracy: 0.7608\n",
            "Epoch 53: val_accuracy did not improve from 0.73762\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.7624 - val_loss: 0.7525 - val_accuracy: 0.7178\n",
            "Epoch 54/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.6852 - accuracy: 0.7708\n",
            "Epoch 54: val_accuracy improved from 0.73762 to 0.76238, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 10ms/step - loss: 0.6868 - accuracy: 0.7702 - val_loss: 0.7774 - val_accuracy: 0.7624\n",
            "Epoch 55/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.6815 - accuracy: 0.7806\n",
            "Epoch 55: val_accuracy did not improve from 0.76238\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7807 - val_loss: 0.8170 - val_accuracy: 0.7574\n",
            "Epoch 56/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.6542 - accuracy: 0.7812\n",
            "Epoch 56: val_accuracy did not improve from 0.76238\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7823 - val_loss: 0.8640 - val_accuracy: 0.6683\n",
            "Epoch 57/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.6646 - accuracy: 0.7874\n",
            "Epoch 57: val_accuracy did not improve from 0.76238\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7884 - val_loss: 0.7721 - val_accuracy: 0.7574\n",
            "Epoch 58/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.6524 - accuracy: 0.7847\n",
            "Epoch 58: val_accuracy did not improve from 0.76238\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.7862 - val_loss: 0.7721 - val_accuracy: 0.7327\n",
            "Epoch 59/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.6315 - accuracy: 0.7841\n",
            "Epoch 59: val_accuracy improved from 0.76238 to 0.76733, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.6339 - accuracy: 0.7840 - val_loss: 0.7351 - val_accuracy: 0.7673\n",
            "Epoch 60/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.6283 - accuracy: 0.7983\n",
            "Epoch 60: val_accuracy did not improve from 0.76733\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7972 - val_loss: 0.7640 - val_accuracy: 0.6980\n",
            "Epoch 61/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.6204 - accuracy: 0.7993\n",
            "Epoch 61: val_accuracy did not improve from 0.76733\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7989 - val_loss: 0.8707 - val_accuracy: 0.6634\n",
            "Epoch 62/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.7930\n",
            "Epoch 62: val_accuracy did not improve from 0.76733\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.7928 - val_loss: 0.6773 - val_accuracy: 0.7624\n",
            "Epoch 63/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.6005 - accuracy: 0.8069\n",
            "Epoch 63: val_accuracy improved from 0.76733 to 0.77228, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 16ms/step - loss: 0.6034 - accuracy: 0.8011 - val_loss: 0.7022 - val_accuracy: 0.7723\n",
            "Epoch 64/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.5821 - accuracy: 0.8142\n",
            "Epoch 64: val_accuracy improved from 0.77228 to 0.77723, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 12ms/step - loss: 0.5800 - accuracy: 0.8155 - val_loss: 0.6698 - val_accuracy: 0.7772\n",
            "Epoch 65/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.5844 - accuracy: 0.8002\n",
            "Epoch 65: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.8011 - val_loss: 0.6396 - val_accuracy: 0.7673\n",
            "Epoch 66/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.5761 - accuracy: 0.8090\n",
            "Epoch 66: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.8066 - val_loss: 0.7656 - val_accuracy: 0.7228\n",
            "Epoch 67/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.5717 - accuracy: 0.8148\n",
            "Epoch 67: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8116 - val_loss: 0.7880 - val_accuracy: 0.6832\n",
            "Epoch 68/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.5609 - accuracy: 0.8076\n",
            "Epoch 68: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8072 - val_loss: 0.6715 - val_accuracy: 0.7525\n",
            "Epoch 69/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.8199\n",
            "Epoch 69: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.8199 - val_loss: 0.6673 - val_accuracy: 0.7426\n",
            "Epoch 70/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.5555 - accuracy: 0.8125\n",
            "Epoch 70: val_accuracy did not improve from 0.77723\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.8144 - val_loss: 0.6559 - val_accuracy: 0.7574\n",
            "Epoch 71/250\n",
            "46/57 [=======================>......] - ETA: 0s - loss: 0.5425 - accuracy: 0.8200\n",
            "Epoch 71: val_accuracy improved from 0.77723 to 0.78713, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.8227 - val_loss: 0.6409 - val_accuracy: 0.7871\n",
            "Epoch 72/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.5360 - accuracy: 0.8189\n",
            "Epoch 72: val_accuracy improved from 0.78713 to 0.80198, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 16ms/step - loss: 0.5391 - accuracy: 0.8155 - val_loss: 0.5659 - val_accuracy: 0.8020\n",
            "Epoch 73/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.5219 - accuracy: 0.8331\n",
            "Epoch 73: val_accuracy did not improve from 0.80198\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.8298 - val_loss: 0.6292 - val_accuracy: 0.7772\n",
            "Epoch 74/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.5193 - accuracy: 0.8272\n",
            "Epoch 74: val_accuracy did not improve from 0.80198\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.8282 - val_loss: 0.5893 - val_accuracy: 0.7970\n",
            "Epoch 75/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.5132 - accuracy: 0.8269\n",
            "Epoch 75: val_accuracy did not improve from 0.80198\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.8232 - val_loss: 0.8376 - val_accuracy: 0.6683\n",
            "Epoch 76/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.5266 - accuracy: 0.8107\n",
            "Epoch 76: val_accuracy did not improve from 0.80198\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.8127 - val_loss: 0.6555 - val_accuracy: 0.7673\n",
            "Epoch 77/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.4986 - accuracy: 0.8394\n",
            "Epoch 77: val_accuracy did not improve from 0.80198\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8337 - val_loss: 0.7018 - val_accuracy: 0.7228\n",
            "Epoch 78/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.5144 - accuracy: 0.8339\n",
            "Epoch 78: val_accuracy improved from 0.80198 to 0.84653, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.5121 - accuracy: 0.8343 - val_loss: 0.5344 - val_accuracy: 0.8465\n",
            "Epoch 79/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4912 - accuracy: 0.8324\n",
            "Epoch 79: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8331 - val_loss: 0.6854 - val_accuracy: 0.7673\n",
            "Epoch 80/250\n",
            "39/57 [===================>..........] - ETA: 0s - loss: 0.4835 - accuracy: 0.8325\n",
            "Epoch 80: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.8232 - val_loss: 0.6136 - val_accuracy: 0.7921\n",
            "Epoch 81/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.4802 - accuracy: 0.8281\n",
            "Epoch 81: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.8293 - val_loss: 0.7244 - val_accuracy: 0.7426\n",
            "Epoch 82/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.4797 - accuracy: 0.8397\n",
            "Epoch 82: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.8398 - val_loss: 0.5838 - val_accuracy: 0.7921\n",
            "Epoch 83/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4770 - accuracy: 0.8403\n",
            "Epoch 83: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.8409 - val_loss: 0.6867 - val_accuracy: 0.7277\n",
            "Epoch 84/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.4703 - accuracy: 0.8355\n",
            "Epoch 84: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8315 - val_loss: 0.5786 - val_accuracy: 0.7970\n",
            "Epoch 85/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4521 - accuracy: 0.8472\n",
            "Epoch 85: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8459 - val_loss: 0.5679 - val_accuracy: 0.8267\n",
            "Epoch 86/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4589 - accuracy: 0.8415\n",
            "Epoch 86: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8425 - val_loss: 0.6763 - val_accuracy: 0.7228\n",
            "Epoch 87/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.4437 - accuracy: 0.8516\n",
            "Epoch 87: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8470 - val_loss: 0.7039 - val_accuracy: 0.7772\n",
            "Epoch 88/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.4637 - accuracy: 0.8367\n",
            "Epoch 88: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.8403 - val_loss: 0.5721 - val_accuracy: 0.8168\n",
            "Epoch 89/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4483 - accuracy: 0.8534\n",
            "Epoch 89: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8536 - val_loss: 0.6685 - val_accuracy: 0.7475\n",
            "Epoch 90/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.4339 - accuracy: 0.8449\n",
            "Epoch 90: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8425 - val_loss: 0.5075 - val_accuracy: 0.8366\n",
            "Epoch 91/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4376 - accuracy: 0.8517\n",
            "Epoch 91: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8519 - val_loss: 0.5593 - val_accuracy: 0.8069\n",
            "Epoch 92/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4233 - accuracy: 0.8472\n",
            "Epoch 92: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8475 - val_loss: 0.5877 - val_accuracy: 0.7673\n",
            "Epoch 93/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.4379 - accuracy: 0.8418\n",
            "Epoch 93: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8486 - val_loss: 0.5148 - val_accuracy: 0.8119\n",
            "Epoch 94/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4277 - accuracy: 0.8494\n",
            "Epoch 94: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8486 - val_loss: 0.5833 - val_accuracy: 0.7871\n",
            "Epoch 95/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.4087 - accuracy: 0.8597\n",
            "Epoch 95: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8564 - val_loss: 0.6006 - val_accuracy: 0.7921\n",
            "Epoch 96/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.4181 - accuracy: 0.8520\n",
            "Epoch 96: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8481 - val_loss: 0.6572 - val_accuracy: 0.7822\n",
            "Epoch 97/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.4033 - accuracy: 0.8597\n",
            "Epoch 97: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8569 - val_loss: 0.5416 - val_accuracy: 0.8020\n",
            "Epoch 98/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.8652\n",
            "Epoch 98: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8652 - val_loss: 0.5954 - val_accuracy: 0.7822\n",
            "Epoch 99/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3998 - accuracy: 0.8738\n",
            "Epoch 99: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8718 - val_loss: 0.6221 - val_accuracy: 0.7822\n",
            "Epoch 100/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.4068 - accuracy: 0.8622\n",
            "Epoch 100: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8630 - val_loss: 0.5366 - val_accuracy: 0.8020\n",
            "Epoch 101/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3861 - accuracy: 0.8597\n",
            "Epoch 101: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8597 - val_loss: 0.4630 - val_accuracy: 0.8366\n",
            "Epoch 102/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.3885 - accuracy: 0.8698\n",
            "Epoch 102: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8691 - val_loss: 0.5121 - val_accuracy: 0.7970\n",
            "Epoch 103/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3799 - accuracy: 0.8663\n",
            "Epoch 103: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8652 - val_loss: 0.6660 - val_accuracy: 0.7426\n",
            "Epoch 104/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3880 - accuracy: 0.8693\n",
            "Epoch 104: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8691 - val_loss: 0.6222 - val_accuracy: 0.7673\n",
            "Epoch 105/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.3964 - accuracy: 0.8585\n",
            "Epoch 105: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8635 - val_loss: 0.5664 - val_accuracy: 0.8267\n",
            "Epoch 106/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3828 - accuracy: 0.8650\n",
            "Epoch 106: val_accuracy did not improve from 0.84653\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8635 - val_loss: 0.4863 - val_accuracy: 0.8416\n",
            "Epoch 107/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8683\n",
            "Epoch 107: val_accuracy improved from 0.84653 to 0.85149, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.3852 - accuracy: 0.8669 - val_loss: 0.4643 - val_accuracy: 0.8515\n",
            "Epoch 108/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8602\n",
            "Epoch 108: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8602 - val_loss: 0.4485 - val_accuracy: 0.8366\n",
            "Epoch 109/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.3890 - accuracy: 0.8634\n",
            "Epoch 109: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8657 - val_loss: 0.6030 - val_accuracy: 0.7475\n",
            "Epoch 110/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8685\n",
            "Epoch 110: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8685 - val_loss: 0.6668 - val_accuracy: 0.7673\n",
            "Epoch 111/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3747 - accuracy: 0.8721\n",
            "Epoch 111: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8685 - val_loss: 0.5908 - val_accuracy: 0.7772\n",
            "Epoch 112/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3563 - accuracy: 0.8847\n",
            "Epoch 112: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8840 - val_loss: 0.4941 - val_accuracy: 0.8218\n",
            "Epoch 113/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3707 - accuracy: 0.8673\n",
            "Epoch 113: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8702 - val_loss: 0.6403 - val_accuracy: 0.7327\n",
            "Epoch 114/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.3506 - accuracy: 0.8802\n",
            "Epoch 114: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8823 - val_loss: 0.5978 - val_accuracy: 0.7921\n",
            "Epoch 115/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.8862\n",
            "Epoch 115: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8867 - val_loss: 0.4789 - val_accuracy: 0.8366\n",
            "Epoch 116/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3616 - accuracy: 0.8732\n",
            "Epoch 116: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8757 - val_loss: 0.5154 - val_accuracy: 0.7921\n",
            "Epoch 117/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.3373 - accuracy: 0.8756\n",
            "Epoch 117: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8751 - val_loss: 0.5342 - val_accuracy: 0.8218\n",
            "Epoch 118/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.3416 - accuracy: 0.8788\n",
            "Epoch 118: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8845 - val_loss: 0.4920 - val_accuracy: 0.8069\n",
            "Epoch 119/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.3405 - accuracy: 0.8854\n",
            "Epoch 119: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3448 - accuracy: 0.8829 - val_loss: 0.5530 - val_accuracy: 0.7921\n",
            "Epoch 120/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3468 - accuracy: 0.8762\n",
            "Epoch 120: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8790 - val_loss: 0.5739 - val_accuracy: 0.7921\n",
            "Epoch 121/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.3414 - accuracy: 0.8789\n",
            "Epoch 121: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8790 - val_loss: 0.5490 - val_accuracy: 0.7723\n",
            "Epoch 122/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.3197 - accuracy: 0.8844\n",
            "Epoch 122: val_accuracy did not improve from 0.85149\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8807 - val_loss: 0.4792 - val_accuracy: 0.8218\n",
            "Epoch 123/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3391 - accuracy: 0.8854\n",
            "Epoch 123: val_accuracy improved from 0.85149 to 0.87624, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 15ms/step - loss: 0.3373 - accuracy: 0.8867 - val_loss: 0.3809 - val_accuracy: 0.8762\n",
            "Epoch 124/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.3255 - accuracy: 0.8833\n",
            "Epoch 124: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.8785 - val_loss: 0.5290 - val_accuracy: 0.7822\n",
            "Epoch 125/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.3172 - accuracy: 0.8954\n",
            "Epoch 125: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8901 - val_loss: 0.4734 - val_accuracy: 0.8366\n",
            "Epoch 126/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.8885\n",
            "Epoch 126: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8812 - val_loss: 0.7258 - val_accuracy: 0.7723\n",
            "Epoch 127/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3128 - accuracy: 0.8943\n",
            "Epoch 127: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8939 - val_loss: 0.5660 - val_accuracy: 0.7822\n",
            "Epoch 128/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3117 - accuracy: 0.8852\n",
            "Epoch 128: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8878 - val_loss: 0.4379 - val_accuracy: 0.8366\n",
            "Epoch 129/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3141 - accuracy: 0.8956\n",
            "Epoch 129: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8967 - val_loss: 0.5991 - val_accuracy: 0.7822\n",
            "Epoch 130/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.3063 - accuracy: 0.8978\n",
            "Epoch 130: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8967 - val_loss: 0.5175 - val_accuracy: 0.8020\n",
            "Epoch 131/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3022 - accuracy: 0.8860\n",
            "Epoch 131: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8829 - val_loss: 0.4490 - val_accuracy: 0.8515\n",
            "Epoch 132/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.3050 - accuracy: 0.8987\n",
            "Epoch 132: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8956 - val_loss: 0.4546 - val_accuracy: 0.8564\n",
            "Epoch 133/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3142 - accuracy: 0.8886\n",
            "Epoch 133: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8856 - val_loss: 0.7134 - val_accuracy: 0.7376\n",
            "Epoch 134/250\n",
            "47/57 [=======================>......] - ETA: 0s - loss: 0.3008 - accuracy: 0.8956\n",
            "Epoch 134: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8961 - val_loss: 0.5101 - val_accuracy: 0.7921\n",
            "Epoch 135/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2998 - accuracy: 0.8930\n",
            "Epoch 135: val_accuracy did not improve from 0.87624\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8906 - val_loss: 0.4665 - val_accuracy: 0.8465\n",
            "Epoch 136/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3196 - accuracy: 0.8858\n",
            "Epoch 136: val_accuracy improved from 0.87624 to 0.89109, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.3178 - accuracy: 0.8867 - val_loss: 0.4153 - val_accuracy: 0.8911\n",
            "Epoch 137/250\n",
            "46/57 [=======================>......] - ETA: 0s - loss: 0.2994 - accuracy: 0.8899\n",
            "Epoch 137: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8939 - val_loss: 0.5375 - val_accuracy: 0.8119\n",
            "Epoch 138/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8932\n",
            "Epoch 138: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8928 - val_loss: 0.4165 - val_accuracy: 0.8465\n",
            "Epoch 139/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8960\n",
            "Epoch 139: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8972 - val_loss: 0.5085 - val_accuracy: 0.8119\n",
            "Epoch 140/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2918 - accuracy: 0.9004\n",
            "Epoch 140: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8956 - val_loss: 0.3904 - val_accuracy: 0.8762\n",
            "Epoch 141/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.3008 - accuracy: 0.8915\n",
            "Epoch 141: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8923 - val_loss: 0.4359 - val_accuracy: 0.8366\n",
            "Epoch 142/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2795 - accuracy: 0.8977\n",
            "Epoch 142: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8956 - val_loss: 0.4741 - val_accuracy: 0.8069\n",
            "Epoch 143/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2822 - accuracy: 0.8983\n",
            "Epoch 143: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8978 - val_loss: 0.3811 - val_accuracy: 0.8713\n",
            "Epoch 144/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2907 - accuracy: 0.8886\n",
            "Epoch 144: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8890 - val_loss: 0.4875 - val_accuracy: 0.8267\n",
            "Epoch 145/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.8976\n",
            "Epoch 145: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8972 - val_loss: 0.5114 - val_accuracy: 0.7921\n",
            "Epoch 146/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2826 - accuracy: 0.8983\n",
            "Epoch 146: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8978 - val_loss: 0.3528 - val_accuracy: 0.8713\n",
            "Epoch 147/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2710 - accuracy: 0.9045\n",
            "Epoch 147: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.9039 - val_loss: 0.3723 - val_accuracy: 0.8564\n",
            "Epoch 148/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2781 - accuracy: 0.8995\n",
            "Epoch 148: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8994 - val_loss: 0.4669 - val_accuracy: 0.8168\n",
            "Epoch 149/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2829 - accuracy: 0.8972\n",
            "Epoch 149: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8989 - val_loss: 0.4183 - val_accuracy: 0.8614\n",
            "Epoch 150/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2747 - accuracy: 0.9087\n",
            "Epoch 150: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2712 - accuracy: 0.9094 - val_loss: 0.3531 - val_accuracy: 0.8663\n",
            "Epoch 151/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2565 - accuracy: 0.9062\n",
            "Epoch 151: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.9066 - val_loss: 0.4177 - val_accuracy: 0.8416\n",
            "Epoch 152/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2595 - accuracy: 0.9068\n",
            "Epoch 152: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9050 - val_loss: 0.4538 - val_accuracy: 0.8416\n",
            "Epoch 153/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2680 - accuracy: 0.9062\n",
            "Epoch 153: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.9044 - val_loss: 0.4130 - val_accuracy: 0.8465\n",
            "Epoch 154/250\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9033\n",
            "Epoch 154: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9033 - val_loss: 0.4126 - val_accuracy: 0.8663\n",
            "Epoch 155/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2571 - accuracy: 0.9131\n",
            "Epoch 155: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.9050 - val_loss: 0.3838 - val_accuracy: 0.8762\n",
            "Epoch 156/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2579 - accuracy: 0.9074\n",
            "Epoch 156: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9066 - val_loss: 0.3493 - val_accuracy: 0.8861\n",
            "Epoch 157/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2684 - accuracy: 0.9033\n",
            "Epoch 157: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9044 - val_loss: 0.3842 - val_accuracy: 0.8614\n",
            "Epoch 158/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2471 - accuracy: 0.9132\n",
            "Epoch 158: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9116 - val_loss: 0.4593 - val_accuracy: 0.8564\n",
            "Epoch 159/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.2635 - accuracy: 0.9004\n",
            "Epoch 159: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.9039 - val_loss: 0.3645 - val_accuracy: 0.8861\n",
            "Epoch 160/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.2558 - accuracy: 0.9126\n",
            "Epoch 160: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9122 - val_loss: 0.4727 - val_accuracy: 0.8267\n",
            "Epoch 161/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2551 - accuracy: 0.9139\n",
            "Epoch 161: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9122 - val_loss: 0.5288 - val_accuracy: 0.7970\n",
            "Epoch 162/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2629 - accuracy: 0.8999\n",
            "Epoch 162: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.8978 - val_loss: 0.4440 - val_accuracy: 0.8218\n",
            "Epoch 163/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2487 - accuracy: 0.9187\n",
            "Epoch 163: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9210 - val_loss: 0.3766 - val_accuracy: 0.8713\n",
            "Epoch 164/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2434 - accuracy: 0.9116\n",
            "Epoch 164: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9105 - val_loss: 0.4738 - val_accuracy: 0.8465\n",
            "Epoch 165/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2576 - accuracy: 0.9149\n",
            "Epoch 165: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9144 - val_loss: 0.3830 - val_accuracy: 0.8812\n",
            "Epoch 166/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2428 - accuracy: 0.9116\n",
            "Epoch 166: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.9127 - val_loss: 0.3882 - val_accuracy: 0.8465\n",
            "Epoch 167/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2407 - accuracy: 0.9103\n",
            "Epoch 167: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9099 - val_loss: 0.5150 - val_accuracy: 0.7772\n",
            "Epoch 168/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2379 - accuracy: 0.9193\n",
            "Epoch 168: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2351 - accuracy: 0.9204 - val_loss: 0.3307 - val_accuracy: 0.8911\n",
            "Epoch 169/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.2364 - accuracy: 0.9160\n",
            "Epoch 169: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2412 - accuracy: 0.9144 - val_loss: 0.4117 - val_accuracy: 0.8317\n",
            "Epoch 170/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.2421 - accuracy: 0.9124\n",
            "Epoch 170: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3378 - val_accuracy: 0.8762\n",
            "Epoch 171/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2438 - accuracy: 0.9131\n",
            "Epoch 171: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2434 - accuracy: 0.9110 - val_loss: 0.5141 - val_accuracy: 0.8069\n",
            "Epoch 172/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2419 - accuracy: 0.9136\n",
            "Epoch 172: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9127 - val_loss: 0.4611 - val_accuracy: 0.8267\n",
            "Epoch 173/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2403 - accuracy: 0.9118\n",
            "Epoch 173: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2382 - accuracy: 0.9133 - val_loss: 0.3788 - val_accuracy: 0.8515\n",
            "Epoch 174/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.2304 - accuracy: 0.9114\n",
            "Epoch 174: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2245 - accuracy: 0.9149 - val_loss: 0.3990 - val_accuracy: 0.8713\n",
            "Epoch 175/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2444 - accuracy: 0.9131\n",
            "Epoch 175: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2423 - accuracy: 0.9138 - val_loss: 0.4559 - val_accuracy: 0.8416\n",
            "Epoch 176/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2335 - accuracy: 0.9086\n",
            "Epoch 176: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9094 - val_loss: 0.4265 - val_accuracy: 0.8168\n",
            "Epoch 177/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2231 - accuracy: 0.9173\n",
            "Epoch 177: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2267 - accuracy: 0.9171 - val_loss: 0.3585 - val_accuracy: 0.8713\n",
            "Epoch 178/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2257 - accuracy: 0.9231\n",
            "Epoch 178: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.9227 - val_loss: 0.4870 - val_accuracy: 0.8515\n",
            "Epoch 179/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2310 - accuracy: 0.9165\n",
            "Epoch 179: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9166 - val_loss: 0.4514 - val_accuracy: 0.8416\n",
            "Epoch 180/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2247 - accuracy: 0.9201\n",
            "Epoch 180: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9199 - val_loss: 0.4039 - val_accuracy: 0.8861\n",
            "Epoch 181/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.2250 - accuracy: 0.9209\n",
            "Epoch 181: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9215 - val_loss: 0.3533 - val_accuracy: 0.8564\n",
            "Epoch 182/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2234 - accuracy: 0.9246\n",
            "Epoch 182: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9221 - val_loss: 0.3729 - val_accuracy: 0.8564\n",
            "Epoch 183/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2233 - accuracy: 0.9145\n",
            "Epoch 183: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9160 - val_loss: 0.3496 - val_accuracy: 0.8911\n",
            "Epoch 184/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.2219 - accuracy: 0.9227\n",
            "Epoch 184: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9221 - val_loss: 0.3698 - val_accuracy: 0.8663\n",
            "Epoch 185/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2170 - accuracy: 0.9287\n",
            "Epoch 185: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2203 - accuracy: 0.9254 - val_loss: 0.4212 - val_accuracy: 0.8317\n",
            "Epoch 186/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2236 - accuracy: 0.9250\n",
            "Epoch 186: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.9249 - val_loss: 0.3672 - val_accuracy: 0.8713\n",
            "Epoch 187/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.9243\n",
            "Epoch 187: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9243 - val_loss: 0.5419 - val_accuracy: 0.8515\n",
            "Epoch 188/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2158 - accuracy: 0.9269\n",
            "Epoch 188: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.9238 - val_loss: 0.4070 - val_accuracy: 0.8465\n",
            "Epoch 189/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2161 - accuracy: 0.9213\n",
            "Epoch 189: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9227 - val_loss: 0.4062 - val_accuracy: 0.8564\n",
            "Epoch 190/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2135 - accuracy: 0.9222\n",
            "Epoch 190: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9204 - val_loss: 0.4034 - val_accuracy: 0.8366\n",
            "Epoch 191/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.2111 - accuracy: 0.9241\n",
            "Epoch 191: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9265 - val_loss: 0.4206 - val_accuracy: 0.8762\n",
            "Epoch 192/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2100 - accuracy: 0.9306\n",
            "Epoch 192: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2122 - accuracy: 0.9282 - val_loss: 0.4221 - val_accuracy: 0.8515\n",
            "Epoch 193/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.2126 - accuracy: 0.9207\n",
            "Epoch 193: val_accuracy did not improve from 0.89109\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9215 - val_loss: 0.4611 - val_accuracy: 0.8366\n",
            "Epoch 194/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.2219 - accuracy: 0.9148\n",
            "Epoch 194: val_accuracy improved from 0.89109 to 0.90099, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 11ms/step - loss: 0.2167 - accuracy: 0.9182 - val_loss: 0.3027 - val_accuracy: 0.9010\n",
            "Epoch 195/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.2037 - accuracy: 0.9213\n",
            "Epoch 195: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9166 - val_loss: 0.3361 - val_accuracy: 0.8812\n",
            "Epoch 196/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1972 - accuracy: 0.9324\n",
            "Epoch 196: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.9331 - val_loss: 0.3850 - val_accuracy: 0.8960\n",
            "Epoch 197/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.1948 - accuracy: 0.9319\n",
            "Epoch 197: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9287 - val_loss: 0.3826 - val_accuracy: 0.8614\n",
            "Epoch 198/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2023 - accuracy: 0.9269\n",
            "Epoch 198: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9271 - val_loss: 0.3290 - val_accuracy: 0.8812\n",
            "Epoch 199/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.1922 - accuracy: 0.9357\n",
            "Epoch 199: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9348 - val_loss: 0.4989 - val_accuracy: 0.8366\n",
            "Epoch 200/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.2084 - accuracy: 0.9231\n",
            "Epoch 200: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9227 - val_loss: 0.4446 - val_accuracy: 0.8812\n",
            "Epoch 201/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1992 - accuracy: 0.9205\n",
            "Epoch 201: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.9199 - val_loss: 0.4262 - val_accuracy: 0.8564\n",
            "Epoch 202/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.2075 - accuracy: 0.9286\n",
            "Epoch 202: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9282 - val_loss: 0.3560 - val_accuracy: 0.8960\n",
            "Epoch 203/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.2056 - accuracy: 0.9216\n",
            "Epoch 203: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9254 - val_loss: 0.3347 - val_accuracy: 0.9010\n",
            "Epoch 204/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1978 - accuracy: 0.9277\n",
            "Epoch 204: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9260 - val_loss: 0.4571 - val_accuracy: 0.8267\n",
            "Epoch 205/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.1896 - accuracy: 0.9337\n",
            "Epoch 205: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9315 - val_loss: 0.4694 - val_accuracy: 0.8465\n",
            "Epoch 206/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.1903 - accuracy: 0.9287\n",
            "Epoch 206: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.9309 - val_loss: 0.3505 - val_accuracy: 0.8762\n",
            "Epoch 207/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9364\n",
            "Epoch 207: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.9370 - val_loss: 0.3130 - val_accuracy: 0.8762\n",
            "Epoch 208/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1947 - accuracy: 0.9403\n",
            "Epoch 208: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9414 - val_loss: 0.3813 - val_accuracy: 0.8713\n",
            "Epoch 209/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1900 - accuracy: 0.9317\n",
            "Epoch 209: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.9315 - val_loss: 0.3774 - val_accuracy: 0.8317\n",
            "Epoch 210/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1967 - accuracy: 0.9347\n",
            "Epoch 210: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9354 - val_loss: 0.3169 - val_accuracy: 0.8960\n",
            "Epoch 211/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1921 - accuracy: 0.9309\n",
            "Epoch 211: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9326 - val_loss: 0.4581 - val_accuracy: 0.8416\n",
            "Epoch 212/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1964 - accuracy: 0.9326\n",
            "Epoch 212: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9343 - val_loss: 0.3244 - val_accuracy: 0.8861\n",
            "Epoch 213/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1914 - accuracy: 0.9320\n",
            "Epoch 213: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.9315 - val_loss: 0.3712 - val_accuracy: 0.8416\n",
            "Epoch 214/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.1774 - accuracy: 0.9369\n",
            "Epoch 214: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9365 - val_loss: 0.3706 - val_accuracy: 0.8713\n",
            "Epoch 215/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1857 - accuracy: 0.9320\n",
            "Epoch 215: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9326 - val_loss: 0.3525 - val_accuracy: 0.8812\n",
            "Epoch 216/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.1966 - accuracy: 0.9319\n",
            "Epoch 216: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.9304 - val_loss: 0.3639 - val_accuracy: 0.8614\n",
            "Epoch 217/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1868 - accuracy: 0.9364\n",
            "Epoch 217: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9359 - val_loss: 0.3307 - val_accuracy: 0.8713\n",
            "Epoch 218/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1910 - accuracy: 0.9301\n",
            "Epoch 218: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9304 - val_loss: 0.8293 - val_accuracy: 0.7475\n",
            "Epoch 219/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1902 - accuracy: 0.9332\n",
            "Epoch 219: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9309 - val_loss: 0.3992 - val_accuracy: 0.8614\n",
            "Epoch 220/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1884 - accuracy: 0.9308\n",
            "Epoch 220: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9315 - val_loss: 0.4054 - val_accuracy: 0.8564\n",
            "Epoch 221/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1863 - accuracy: 0.9279\n",
            "Epoch 221: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1859 - accuracy: 0.9287 - val_loss: 0.3125 - val_accuracy: 0.9010\n",
            "Epoch 222/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.9345\n",
            "Epoch 222: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.9381 - val_loss: 0.3129 - val_accuracy: 0.8861\n",
            "Epoch 223/250\n",
            "47/57 [=======================>......] - ETA: 0s - loss: 0.1775 - accuracy: 0.9382\n",
            "Epoch 223: val_accuracy did not improve from 0.90099\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1816 - accuracy: 0.9331 - val_loss: 0.4769 - val_accuracy: 0.8218\n",
            "Epoch 224/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.1898 - accuracy: 0.9290\n",
            "Epoch 224: val_accuracy improved from 0.90099 to 0.91089, saving model to /content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/57 [==============================] - 1s 16ms/step - loss: 0.1829 - accuracy: 0.9337 - val_loss: 0.2751 - val_accuracy: 0.9109\n",
            "Epoch 225/250\n",
            "46/57 [=======================>......] - ETA: 0s - loss: 0.1683 - accuracy: 0.9429\n",
            "Epoch 225: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.9425 - val_loss: 0.3748 - val_accuracy: 0.8960\n",
            "Epoch 226/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.1728 - accuracy: 0.9304\n",
            "Epoch 226: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9309 - val_loss: 0.3118 - val_accuracy: 0.8812\n",
            "Epoch 227/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9381\n",
            "Epoch 227: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9381 - val_loss: 0.2621 - val_accuracy: 0.9109\n",
            "Epoch 228/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.1759 - accuracy: 0.9381\n",
            "Epoch 228: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9376 - val_loss: 0.3479 - val_accuracy: 0.8861\n",
            "Epoch 229/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1826 - accuracy: 0.9326\n",
            "Epoch 229: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9343 - val_loss: 0.5001 - val_accuracy: 0.8564\n",
            "Epoch 230/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1857 - accuracy: 0.9334\n",
            "Epoch 230: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1833 - accuracy: 0.9348 - val_loss: 0.5503 - val_accuracy: 0.8218\n",
            "Epoch 231/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.1794 - accuracy: 0.9355\n",
            "Epoch 231: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9320 - val_loss: 0.3297 - val_accuracy: 0.8960\n",
            "Epoch 232/250\n",
            "55/57 [===========================>..] - ETA: 0s - loss: 0.1712 - accuracy: 0.9358\n",
            "Epoch 232: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9359 - val_loss: 0.2487 - val_accuracy: 0.9109\n",
            "Epoch 233/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9403\n",
            "Epoch 233: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9403 - val_loss: 0.3571 - val_accuracy: 0.8812\n",
            "Epoch 234/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.9315\n",
            "Epoch 234: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9331 - val_loss: 0.3550 - val_accuracy: 0.8762\n",
            "Epoch 235/250\n",
            "56/57 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9381\n",
            "Epoch 235: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9376 - val_loss: 0.3319 - val_accuracy: 0.8960\n",
            "Epoch 236/250\n",
            "50/57 [=========================>....] - ETA: 0s - loss: 0.1714 - accuracy: 0.9350\n",
            "Epoch 236: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9381 - val_loss: 0.5601 - val_accuracy: 0.8168\n",
            "Epoch 237/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1723 - accuracy: 0.9398\n",
            "Epoch 237: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9409 - val_loss: 0.4029 - val_accuracy: 0.8416\n",
            "Epoch 238/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.1638 - accuracy: 0.9432\n",
            "Epoch 238: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9442 - val_loss: 0.2838 - val_accuracy: 0.8812\n",
            "Epoch 239/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1654 - accuracy: 0.9381\n",
            "Epoch 239: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9370 - val_loss: 0.3368 - val_accuracy: 0.8663\n",
            "Epoch 240/250\n",
            "49/57 [========================>.....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9381\n",
            "Epoch 240: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9359 - val_loss: 0.3376 - val_accuracy: 0.8762\n",
            "Epoch 241/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1608 - accuracy: 0.9447\n",
            "Epoch 241: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.9475 - val_loss: 0.6251 - val_accuracy: 0.8168\n",
            "Epoch 242/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1668 - accuracy: 0.9363\n",
            "Epoch 242: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9381 - val_loss: 0.4050 - val_accuracy: 0.8465\n",
            "Epoch 243/250\n",
            "52/57 [==========================>...] - ETA: 0s - loss: 0.1653 - accuracy: 0.9369\n",
            "Epoch 243: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9365 - val_loss: 0.4694 - val_accuracy: 0.8416\n",
            "Epoch 244/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1564 - accuracy: 0.9468\n",
            "Epoch 244: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9448 - val_loss: 0.3784 - val_accuracy: 0.8614\n",
            "Epoch 245/250\n",
            "51/57 [=========================>....] - ETA: 0s - loss: 0.1618 - accuracy: 0.9467\n",
            "Epoch 245: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9464 - val_loss: 0.3051 - val_accuracy: 0.8762\n",
            "Epoch 246/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.9316\n",
            "Epoch 246: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9348 - val_loss: 0.3981 - val_accuracy: 0.8515\n",
            "Epoch 247/250\n",
            "53/57 [==========================>...] - ETA: 0s - loss: 0.1677 - accuracy: 0.9399\n",
            "Epoch 247: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9403 - val_loss: 0.4333 - val_accuracy: 0.8564\n",
            "Epoch 248/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1599 - accuracy: 0.9444\n",
            "Epoch 248: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9420 - val_loss: 0.4445 - val_accuracy: 0.8713\n",
            "Epoch 249/250\n",
            "48/57 [========================>.....] - ETA: 0s - loss: 0.1591 - accuracy: 0.9479\n",
            "Epoch 249: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1582 - accuracy: 0.9475 - val_loss: 0.3925 - val_accuracy: 0.8663\n",
            "Epoch 250/250\n",
            "54/57 [===========================>..] - ETA: 0s - loss: 0.1649 - accuracy: 0.9352\n",
            "Epoch 250: val_accuracy did not improve from 0.91089\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9359 - val_loss: 0.2686 - val_accuracy: 0.8911\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2', \n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "history2=Model.fit(bottleneck_features_train_ResNet50, train_targets, validation_split=0.1, epochs=250, batch_size=32, callbacks=[checkpointer], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STnPSANyA_NK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5586c875-d8b2-4aa6-c4ab-9f61150d56cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Time Taken: 31.787902355194092 seconds\n"
          ]
        }
      ],
      "source": [
        "Model2 = Sequential()\n",
        "Model2.add(Dense(800, activation='relu',kernel_initializer='glorot_normal'))\n",
        "Model2.add(Dense(36, activation='softmax', kernel_initializer='glorot_normal'))\n",
        "Model2.load_weights('/content/saved_models/weights.best.F.hdf5_TransferLearning_ResNet50_2')\n",
        "import time\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "ResNet50_predictions = [Model2.predict(np.expand_dims(tensor, axis=0))[0] for tensor in bottleneck_features_test_ResNet50 ]\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "print(\"Time Taken: {} seconds\".format(end_time-start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phHmLvqNBKPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b4b146-aefa-4ed9-d88d-a203acd497e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.70        16\n",
            "           1       0.83      0.91      0.87        11\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       1.00      0.92      0.96        13\n",
            "           5       1.00      1.00      1.00        17\n",
            "           6       1.00      0.67      0.80        18\n",
            "           7       1.00      0.92      0.96        13\n",
            "           8       1.00      1.00      1.00        16\n",
            "           9       1.00      1.00      1.00        17\n",
            "          10       0.90      1.00      0.95        19\n",
            "          11       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00        11\n",
            "          13       1.00      0.95      0.97        20\n",
            "          14       1.00      1.00      1.00        19\n",
            "          15       1.00      1.00      1.00        11\n",
            "          16       0.90      0.90      0.90        21\n",
            "          17       0.83      1.00      0.91        10\n",
            "          18       1.00      0.92      0.96        13\n",
            "          19       1.00      0.75      0.86        16\n",
            "          20       0.93      1.00      0.97        14\n",
            "          21       1.00      1.00      1.00        10\n",
            "          22       0.79      1.00      0.88        11\n",
            "          23       0.92      0.73      0.81        15\n",
            "          24       1.00      0.50      0.67        12\n",
            "          25       1.00      1.00      1.00        17\n",
            "          26       1.00      1.00      1.00        20\n",
            "          27       1.00      0.91      0.95        11\n",
            "          28       0.85      1.00      0.92        11\n",
            "          29       1.00      0.82      0.90        11\n",
            "          30       0.94      0.89      0.91        18\n",
            "          31       1.00      0.86      0.92         7\n",
            "          32       0.57      1.00      0.73         8\n",
            "          33       1.00      0.89      0.94         9\n",
            "          34       0.93      0.78      0.85        18\n",
            "          35       0.80      0.86      0.83        14\n",
            "\n",
            "    accuracy                           0.92       503\n",
            "   macro avg       0.93      0.92      0.92       503\n",
            "weighted avg       0.94      0.92      0.92       503\n",
            "\n",
            "[[16  0  0 ...  0  0  0]\n",
            " [ 0 10  0 ...  0  0  1]\n",
            " [ 2  0 10 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  8  0  0]\n",
            " [ 0  0  0 ...  0 14  1]\n",
            " [ 0  2  0 ...  0  0 12]]\n"
          ]
        }
      ],
      "source": [
        "## report test accuracy\n",
        "predicted_classes = np.argmax(np.round(ResNet50_predictions),axis=1)\n",
        "test_classes = np.argmax(np.round(test_targets),axis=1)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_classes, predicted_classes))\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_mtx = confusion_matrix(test_classes, predicted_classes)\n",
        "print(confusion_mtx)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}